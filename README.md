# RT-TM: RealTime TensorMath

*A Type-Safe, Depth-Scheduled ML Runtime for Modern CPUs*

**One-liner vision:**

> ***A static-dynamic hybrid ML runtime that compiles your model graph into a lock-free, thread-coordinated execution plan with zero vtables, zero RTTI, and pure type safety ‚Äî tuned for real-time CPU inference.***

---

**RT-TM** is a new kind of machine learning runtime:
It transforms models like Meta's LLaMA 3 into **fully type-specialized, depth-indexed op graphs** that execute using a custom-designed hybrid thread scheduler.
Each op is stored as a concrete type ‚Äî no virtual dispatch ‚Äî and is scheduled according to its depth and dataflow dependencies.

The result is a runtime that:

‚úÖ ***Executes continuous op chains without synchronization overhead***  
‚úÖ ***Synchronizes only at blocking ops (e.g. matrix multiplications)***  
‚úÖ ***Uses a depth-indexed threadpool with per-thread op chains***  
‚úÖ ***Has cache-optimized storage for all ops ‚Äî no vtables***  
‚úÖ ***Supports quantized types and arbitrary op type specializations***  
‚úÖ ***Exposes a clean, pure C++ API***  

---

# üñ•Ô∏è **Sample Usage (from RT-TM API)**

```cpp
static constexpr rt_tm::model_config model_config{ .arch = rt_tm::model_arch::llama, .exceptions = false };

// Parse model from GGUF
auto model_graph = rt_tm::harbinger<model_config>::parse_model_graph<rt_tm::model_format::gguf>(argv[2]);

// Create op graph with thread configuration
rt_tm::op_graph_config graph_config{ .num_threads = 12 };
rt_tm::op_graph<model_config> op_graph{ rt_tm::harbinger<model_config>::create_op_graph(graph_config, model_graph) };

// Setup input stream
rt_tm::input_session_config session_config{ .stream = std::cin, .max_tokens = 1024 };
rt_tm::input_session input_session{ session_config };

// Main inference loop
while (input_session) {
    op_graph.process_input(input_session);
}
```

---

# üó∫Ô∏è **Execution Model Diagram**

```
Model Parsing (GGUF) ‚Üí model_graph (static topology + metadata)
                          ‚Üì
harbinger::create_op_graph() ‚Üí op_graph<model_config>
                          ‚Üì
op_graph {
    op_graph_bases {
        op_graph_bases_op<op_enum_value> ‚Üí vector<typed core<T>>
    }
    device_registry {
        thread_pool {
            scheduler_depths {
                scheduler_depth<depth N> {
                    op_holder<input_count> {
                        vector<cpu_op_core_thread<input_count>>
                    }
                    thread-coordinated op_chain execution
                }
            }
        }
    }
}
                          ‚Üì
process_input(input_session):
    ‚Üí resets state
    ‚Üí schedules execution
    ‚Üí executes tasks across thread pool
```

---

# üí° **Key Innovations**

* **Static-dynamic hybrid execution:** compile-time typed op graph + runtime depth scheduling  
* **Per-depth continuous-op bursting:** threads blast forward until sync barrier required  
* **Zero vtables / RTTI:** all ops are concrete types, not heap-allocated polymorphic instances  
* **Fast dispatch:** compile-time generated dispatch chains per op type / type group  
* **Extensible:** easily add support for quantized ops, arch-specific kernels (AVX, AVX512, SVE)  

---

# üöÄ **Current Status**

‚úÖ Core architecture implemented  
‚úÖ Working op graph execution  
‚úÖ Depth-aware thread scheduling proven  
‚úÖ LLaMA 3 GGUF parsing working  
‚úÖ Static op graph storage system built  

Coming next:

* Quantized op specialization  
* Memory arena  
* Profiler  
* Full LLaMA forward pass benchmarks  
* Public engine release  

---

# ‚ú® **Conclusion**

RT-TM represents an attempt to rethink how CPU-based ML runtimes are structured.
Instead of treating execution as a stream of generic ops with runtime indirection, RT-TM fully embraces **C++ static typing and compile-time specialization**, turning ML models into highly optimized, depth-aware execution pipelines that can run in real time on modern CPUs.

---