────────────────────────────────────────
Tensor: blk.0.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: token_embd.weight             │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 128256 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: leaf_2                        │
────────────────────────────────────────
Type:       i32                      
Dimensions: [2 × 1 × 1 × 1]       
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: leaf_4                        │
────────────────────────────────────────
Type:       i32                      
Dimensions: [2 × 1 × 1 × 1]       
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: rope_freqs.weight             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [64 × 1 × 1 × 1]      
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l0                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l0                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: leaf_10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 64 × 1 × 1]     
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.0.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l1                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l1                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.1.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l2                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l2                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.2.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l3                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l3                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.3.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l4                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l4                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.4.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l5                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l5                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.5.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l6                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l6                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.6.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l7                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l7                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.7.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l8                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l8                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.attn_q.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.8.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.attn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.attn_k.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.attn_v.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l9                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l9                    │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.ffn_down.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.ffn_gate.weight         │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.attn_output.weight      │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.ffn_norm.weight         │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.9.ffn_up.weight           │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l10                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l10                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.10.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l11                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l11                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.11.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l12                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l12                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.12.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l13                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l13                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.13.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l14                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l14                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.14.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l15                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l15                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.15.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l16                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l16                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.16.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l17                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l17                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.17.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l18                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l18                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.18.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l19                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l19                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.19.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l20                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l20                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.20.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l21                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l21                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.21.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l22                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l22                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.22.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l23                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l23                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.23.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l24                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l24                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.24.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l25                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l25                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.25.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l26                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l26                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.26.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l27                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l27                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.27.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l28                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l28                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.28.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l29                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l29                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.29.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l30                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l30                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.attn_q.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.30.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.attn_norm.weight       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.attn_k.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.attn_v.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 1024 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l31                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l31                   │
────────────────────────────────────────
Type:       f16                      
Dimensions: [1024 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: output.weight                 │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 128256 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.ffn_down.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [14336 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.ffn_gate.weight        │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.attn_output.weight     │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 4096 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: leaf_356                      │
────────────────────────────────────────
Type:       i32                      
Dimensions: [1 × 1 × 1 × 1]       
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.ffn_norm.weight        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: blk.31.ffn_up.weight          │
────────────────────────────────────────
Type:       q8_0                     
Dimensions: [4096 × 14336 × 1 × 1] 
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: output_norm.weight            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  NONE                     
Inputs:     0                        
─────────────────────────────────────────
────────────────────────────────────────
Tensor: inp_embd                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  GET_ROWS                 
Inputs:     2                        
    Tensor: token_embd.weight            
    Type:       q8_0                     
    Dimensions: [4096 × 128256 × 1 × 1] 
    Operation:  NONE                     
    Tensor: leaf_2                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: inp_embd                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  GET_ROWS                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-0                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-0                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.0.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-0                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-0 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-0                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-0 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-0                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-0 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-0                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-0 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-0                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-0                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l0 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l0                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l0 (view) (copy of Kcur-0) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-0                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l0 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-0 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-0                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-0 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-0 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l0 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l0                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l0 (view) (copy of Vcur-0 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-0 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l0 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l0 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l0                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l0 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l0 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l0 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l0                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l0 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l0 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-0 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-0                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l0 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-0 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_22                      
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l0 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_23                      
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_24                      
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-0                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-0                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-0                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-0                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-0                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: inp_embd                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  GET_ROWS                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-0                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-0                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-0                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-0                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.0.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-0                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-0                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-0                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-0                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-0                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-0                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-0                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-0                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-0                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-0                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.0.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-0               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-0                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-0                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-0                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-0                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-1                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-1                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.1.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-1                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-1 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-1                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-1 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-1                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-1 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-1                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-1 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-1                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-1                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l1 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l1                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l1 (view) (copy of Kcur-1) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-1                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l1 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-1 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-1                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-1 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-1 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l1 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l1                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l1 (view) (copy of Vcur-1 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-1 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l1 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l1 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l1                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l1 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l1 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l1 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l1                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l1 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l1 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-1 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-1                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_58                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l1 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-1 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_59                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_58                      
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_60                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l1 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_59                      
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_60                      
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-1                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-1                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-1                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-1                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-1                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-0                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-1                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-1                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-1                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-1                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.1.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-1                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-1                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-1                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-1                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-1                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-1                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-1                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-1                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-1                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-1                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.1.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-1               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-1                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-1                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-1                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-1                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-2                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-2                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.2.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-2                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-2 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-2                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-2 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-2                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-2 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-2                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-2 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-2                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-2                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l2 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l2                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l2 (view) (copy of Kcur-2) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-2                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l2 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-2 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-2                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-2 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-2 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l2 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l2                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l2 (view) (copy of Vcur-2 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-2 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l2 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l2 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l2                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l2 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l2 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l2 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l2                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l2 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l2 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-2 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-2                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_94                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l2 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-2 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_95                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_94                      
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_96                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l2 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_95                      
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_96                      
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-2                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-2                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-2                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-2                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-2                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-1                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-2                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-2                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-2                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-2                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.2.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-2                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-2                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-2                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-2                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-2                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-2                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-2                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-2                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-2                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-2                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.2.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-2               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-2                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-2                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-2                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-2                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-3                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-3                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.3.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-3                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-3 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-3                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-3 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-3                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-3 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-3                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-3 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-3                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-3                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l3 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l3                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l3 (view) (copy of Kcur-3) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-3                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l3 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-3 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-3                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-3 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-3 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l3 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l3                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l3 (view) (copy of Vcur-3 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-3 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l3 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l3 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l3                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l3 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l3 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l3 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l3                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l3 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l3 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-3 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-3                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_130                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l3 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-3 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_131                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_130                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_132                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l3 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_131                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_132                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-3                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-3                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-3                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-3                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-3                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-2                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-3                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-3                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-3                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-3                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.3.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-3                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-3                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-3                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-3                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-3                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-3                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-3                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-3                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-3                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-3                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.3.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-3               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-3                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-3                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-3                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-3                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-4                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-4                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.4.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-4                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-4 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-4                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-4 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-4                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-4 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-4                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-4 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-4                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-4                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l4 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l4                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l4 (view) (copy of Kcur-4) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-4                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l4 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-4 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-4                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-4 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-4 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l4 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l4                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l4 (view) (copy of Vcur-4 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-4 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l4 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l4 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l4                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l4 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l4 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l4 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l4                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l4 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l4 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-4 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-4                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_166                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l4 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-4 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_167                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_166                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_168                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l4 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_167                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_168                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-4                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-4                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-4                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-4                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-4                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-3                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-4                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-4                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-4                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-4                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.4.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-4                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-4                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-4                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-4                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-4                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-4                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-4                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-4                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-4                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-4                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.4.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-4               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-4                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-4                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-4                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-4                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-5                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-5                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.5.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-5                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-5 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-5                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-5 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-5                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-5 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-5                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-5 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-5                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-5                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l5 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l5                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l5 (view) (copy of Kcur-5) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-5                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l5 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-5 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-5                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-5 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-5 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l5 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l5                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l5 (view) (copy of Vcur-5 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-5 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l5 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l5 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l5                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l5 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l5 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l5 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l5                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l5 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l5 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-5 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-5                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_202                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l5 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-5 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_203                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_202                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_204                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l5 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_203                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_204                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-5                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-5                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-5                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-5                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-5                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-4                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-5                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-5                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-5                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-5                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.5.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-5                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-5                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-5                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-5                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-5                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-5                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-5                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-5                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-5                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-5                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.5.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-5               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-5                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-5                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-5                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-5                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-6                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-6                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.6.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-6                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-6 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-6                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-6 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-6                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-6 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-6                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-6 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-6                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-6                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l6 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l6                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l6 (view) (copy of Kcur-6) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-6                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l6 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-6 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-6                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-6 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-6 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l6 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l6                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l6 (view) (copy of Vcur-6 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-6 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l6 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l6 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l6                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l6 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l6 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l6 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l6                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l6 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l6 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-6 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-6                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_238                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l6 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-6 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_239                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_238                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_240                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l6 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_239                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_240                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-6                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-6                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-6                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-6                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-6                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-5                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-6                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-6                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-6                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-6                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.6.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-6                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-6                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-6                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-6                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-6                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-6                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-6                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-6                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-6                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-6                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.6.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-6               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-6                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-6                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-6                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-6                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-7                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-7                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.7.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-7                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-7 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-7                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-7 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-7                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-7 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-7                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-7 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-7                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-7                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l7 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l7                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l7 (view) (copy of Kcur-7) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-7                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l7 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-7 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-7                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-7 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-7 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l7 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l7                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l7 (view) (copy of Vcur-7 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-7 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l7 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l7 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l7                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l7 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l7 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l7 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l7                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l7 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l7 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-7 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-7                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_274                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l7 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-7 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_275                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_274                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_276                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l7 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_275                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_276                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-7                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-7                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-7                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-7                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-7                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-6                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-7                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-7                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-7                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-7                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.7.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-7                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-7                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-7                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-7                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-7                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-7                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-7                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-7                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-7                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-7                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.7.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-7               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-7                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-7                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-7                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-7                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-8                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-8                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.8.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-8                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-8 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-8                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-8 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-8                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-8 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-8                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-8 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-8                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-8                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l8 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l8                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l8 (view) (copy of Kcur-8) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-8                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l8 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-8 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-8                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-8 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-8 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l8 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l8                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l8 (view) (copy of Vcur-8 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-8 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l8 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l8 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l8                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l8 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l8 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l8 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l8                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l8 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l8 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-8 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-8                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_310                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l8 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-8 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_311                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_310                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_312                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l8 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_311                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_312                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-8                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-8                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-8                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-8                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-8                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-7                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-8                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-8                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-8                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-8                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.8.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-8                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-8                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-8                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-8                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-8                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-8                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-8                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-8                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-8                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-8                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.8.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-8               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-8                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-8                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-8                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-8                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-9                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-9                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.9.attn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.attn_q.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-9                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-9 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-9                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-9 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.attn_k.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-9                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-9 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-9                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-9 (reshaped)            
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.attn_v.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-9                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-9                       
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l9 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l9                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l9 (view) (copy of Kcur-9) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-9                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l9 (view)            
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-9 (reshaped)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-9                       
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-9 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-9 (reshaped)            
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l9 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l9                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l9 (view) (copy of Vcur-9 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-9 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l9 (view)            
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l9 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l9                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l9 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l9 (view)            
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l9 (view)             │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l9                   
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l9 (view) (permuted)  │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l9 (view)            
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-9 (permuted)             │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-9                       
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_346                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l9 (view) (permuted) 
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-9 (permuted)            
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_347                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_346                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_348                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l9 (view) (permuted) 
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_347                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_348                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-9                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-9                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.attn_output.weight     
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-9                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-9                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-9                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-8                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-9                        │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-9                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-9                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-9                       
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.9.ffn_norm.weight        
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-9                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.ffn_gate.weight        
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-9                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-9                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-9                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-9                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.ffn_up.weight          
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-9                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-9                │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-9                   
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-9                     
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-9                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.9.ffn_down.weight        
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-9               
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-9                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-9                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-9                    
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-9                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-10                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-10                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.10.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-10                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-10 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-10                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-10 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-10                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-10 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-10                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-10 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-10                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-10                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l10 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l10                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l10 (view) (copy of Kcur-10) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-10                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l10 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-10 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-10                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-10 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-10 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l10 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l10                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l10 (view) (copy of Vcur-10 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-10 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l10 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l10 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l10                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l10 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l10 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l10 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l10                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l10 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l10 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-10 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-10                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_382                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l10 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-10 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_383                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_382                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_384                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l10 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_383                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_384                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-10                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-10                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-10                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-10                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-10                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-9                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-10                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-10                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-10                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-10                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.10.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-10                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-10                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-10                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-10                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-10                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-10                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-10               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-10                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-10                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-10                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.10.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-10              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-10                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-10                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-10                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-10                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-11                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-11                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.11.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-11                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-11 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-11                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-11 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-11                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-11 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-11                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-11 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-11                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-11                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l11 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l11                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l11 (view) (copy of Kcur-11) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-11                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l11 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-11 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-11                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-11 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-11 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l11 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l11                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l11 (view) (copy of Vcur-11 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-11 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l11 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l11 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l11                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l11 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l11 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l11 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l11                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l11 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l11 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-11 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-11                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_418                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l11 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-11 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_419                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_418                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_420                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l11 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_419                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_420                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-11                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-11                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-11                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-11                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-11                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-10                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-11                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-11                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-11                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-11                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.11.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-11                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-11                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-11                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-11                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-11                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-11                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-11               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-11                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-11                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-11                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.11.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-11              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-11                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-11                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-11                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-11                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-12                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-12                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.12.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-12                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-12 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-12                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-12 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-12                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-12 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-12                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-12 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-12                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-12                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l12 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l12                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l12 (view) (copy of Kcur-12) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-12                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l12 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-12 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-12                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-12 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-12 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l12 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l12                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l12 (view) (copy of Vcur-12 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-12 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l12 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l12 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l12                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l12 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l12 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l12 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l12                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l12 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l12 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-12 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-12                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_454                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l12 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-12 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_455                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_454                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_456                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l12 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_455                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_456                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-12                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-12                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-12                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-12                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-12                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-11                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-12                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-12                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-12                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-12                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.12.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-12                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-12                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-12                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-12                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-12                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-12                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-12               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-12                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-12                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-12                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.12.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-12              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-12                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-12                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-12                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-12                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-13                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-13                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.13.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-13                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-13 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-13                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-13 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-13                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-13 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-13                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-13 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-13                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-13                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l13 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l13                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l13 (view) (copy of Kcur-13) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-13                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l13 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-13 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-13                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-13 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-13 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l13 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l13                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l13 (view) (copy of Vcur-13 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-13 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l13 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l13 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l13                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l13 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l13 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l13 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l13                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l13 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l13 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-13 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-13                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_490                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l13 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-13 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_491                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_490                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_492                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l13 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_491                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_492                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-13                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-13                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-13                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-13                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-13                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-12                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-13                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-13                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-13                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-13                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.13.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-13                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-13                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-13                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-13                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-13                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-13                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-13               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-13                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-13                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-13                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.13.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-13              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-13                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-13                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-13                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-13                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-14                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-14                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.14.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-14                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-14 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-14                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-14 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-14                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-14 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-14                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-14 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-14                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-14                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l14 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l14                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l14 (view) (copy of Kcur-14) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-14                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l14 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-14 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-14                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-14 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-14 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l14 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l14                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l14 (view) (copy of Vcur-14 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-14 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l14 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l14 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l14                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l14 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l14 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l14 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l14                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l14 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l14 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-14 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-14                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_526                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l14 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-14 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_527                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_526                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_528                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l14 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_527                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_528                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-14                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-14                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-14                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-14                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-14                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-13                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-14                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-14                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-14                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-14                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.14.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-14                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-14                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-14                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-14                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-14                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-14                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-14               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-14                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-14                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-14                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.14.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-14              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-14                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-14                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-14                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-14                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-15                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-15                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.15.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-15                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-15 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-15                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-15 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-15                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-15 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-15                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-15 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-15                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-15                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l15 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l15                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l15 (view) (copy of Kcur-15) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-15                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l15 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-15 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-15                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-15 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-15 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l15 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l15                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l15 (view) (copy of Vcur-15 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-15 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l15 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l15 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l15                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l15 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l15 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l15 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l15                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l15 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l15 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-15 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-15                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_562                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l15 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-15 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_563                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_562                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_564                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l15 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_563                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_564                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-15                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-15                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-15                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-15                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-15                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-14                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-15                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-15                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-15                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-15                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.15.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-15                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-15                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-15                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-15                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-15                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-15                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-15               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-15                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-15                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-15                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.15.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-15              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-15                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-15                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-15                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-15                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-16                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-16                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.16.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-16                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-16 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-16                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-16 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-16                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-16 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-16                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-16 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-16                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-16                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l16 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l16                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l16 (view) (copy of Kcur-16) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-16                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l16 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-16 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-16                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-16 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-16 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l16 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l16                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l16 (view) (copy of Vcur-16 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-16 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l16 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l16 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l16                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l16 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l16 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l16 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l16                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l16 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l16 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-16 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-16                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_598                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l16 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-16 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_599                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_598                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_600                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l16 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_599                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_600                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-16                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-16                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-16                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-16                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-16                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-15                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-16                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-16                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-16                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-16                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.16.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-16                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-16                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-16                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-16                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-16                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-16                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-16               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-16                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-16                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-16                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.16.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-16              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-16                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-16                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-16                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-16                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-17                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-17                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.17.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-17                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-17 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-17                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-17 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-17                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-17 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-17                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-17 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-17                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-17                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l17 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l17                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l17 (view) (copy of Kcur-17) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-17                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l17 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-17 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-17                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-17 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-17 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l17 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l17                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l17 (view) (copy of Vcur-17 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-17 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l17 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l17 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l17                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l17 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l17 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l17 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l17                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l17 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l17 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-17 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-17                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_634                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l17 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-17 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_635                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_634                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_636                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l17 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_635                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_636                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-17                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-17                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-17                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-17                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-17                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-16                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-17                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-17                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-17                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-17                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.17.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-17                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-17                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-17                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-17                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-17                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-17                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-17               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-17                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-17                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-17                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.17.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-17              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-17                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-17                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-17                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-17                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-18                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-18                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.18.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-18                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-18 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-18                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-18 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-18                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-18 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-18                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-18 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-18                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-18                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l18 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l18                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l18 (view) (copy of Kcur-18) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-18                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l18 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-18 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-18                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-18 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-18 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l18 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l18                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l18 (view) (copy of Vcur-18 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-18 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l18 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l18 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l18                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l18 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l18 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l18 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l18                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l18 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l18 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-18 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-18                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_670                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l18 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-18 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_671                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_670                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_672                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l18 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_671                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_672                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-18                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-18                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-18                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-18                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-18                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-17                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-18                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-18                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-18                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-18                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.18.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-18                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-18                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-18                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-18                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-18                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-18                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-18               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-18                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-18                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-18                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.18.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-18              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-18                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-18                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-18                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-18                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-19                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-19                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.19.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-19                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-19 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-19                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-19 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-19                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-19 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-19                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-19 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-19                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-19                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l19 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l19                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l19 (view) (copy of Kcur-19) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-19                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l19 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-19 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-19                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-19 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-19 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l19 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l19                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l19 (view) (copy of Vcur-19 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-19 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l19 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l19 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l19                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l19 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l19 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l19 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l19                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l19 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l19 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-19 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-19                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_706                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l19 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-19 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_707                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_706                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_708                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l19 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_707                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_708                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-19                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-19                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-19                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-19                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-19                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-18                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-19                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-19                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-19                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-19                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.19.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-19                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-19                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-19                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-19                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-19                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-19                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-19               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-19                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-19                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-19                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.19.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-19              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-19                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-19                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-19                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-19                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-20                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-20                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.20.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-20                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-20 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-20                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-20 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-20                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-20 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-20                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-20 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-20                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-20                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l20 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l20                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l20 (view) (copy of Kcur-20) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-20                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l20 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-20 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-20                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-20 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-20 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l20 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l20                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l20 (view) (copy of Vcur-20 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-20 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l20 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l20 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l20                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l20 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l20 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l20 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l20                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l20 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l20 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-20 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-20                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_742                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l20 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-20 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_743                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_742                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_744                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l20 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_743                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_744                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-20                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-20                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-20                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-20                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-20                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-19                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-20                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-20                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-20                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-20                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.20.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-20                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-20                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-20                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-20                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-20                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-20                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-20               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-20                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-20                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-20                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.20.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-20              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-20                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-20                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-20                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-20                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-21                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-21                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.21.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-21                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-21 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-21                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-21 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-21                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-21 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-21                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-21 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-21                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-21                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l21 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l21                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l21 (view) (copy of Kcur-21) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-21                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l21 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-21 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-21                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-21 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-21 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l21 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l21                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l21 (view) (copy of Vcur-21 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-21 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l21 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l21 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l21                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l21 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l21 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l21 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l21                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l21 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l21 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-21 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-21                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_778                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l21 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-21 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_779                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_778                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_780                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l21 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_779                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_780                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-21                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-21                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-21                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-21                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-21                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-20                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-21                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-21                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-21                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-21                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.21.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-21                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-21                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-21                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-21                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-21                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-21                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-21               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-21                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-21                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-21                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.21.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-21              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-21                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-21                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-21                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-21                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-22                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-22                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.22.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-22                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-22 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-22                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-22 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-22                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-22 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-22                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-22 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-22                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-22                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l22 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l22                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l22 (view) (copy of Kcur-22) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-22                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l22 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-22 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-22                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-22 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-22 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l22 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l22                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l22 (view) (copy of Vcur-22 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-22 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l22 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l22 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l22                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l22 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l22 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l22 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l22                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l22 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l22 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-22 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-22                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_814                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l22 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-22 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_815                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_814                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_816                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l22 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_815                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_816                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-22                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-22                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-22                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-22                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-22                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-21                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-22                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-22                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-22                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-22                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.22.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-22                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-22                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-22                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-22                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-22                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-22                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-22               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-22                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-22                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-22                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.22.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-22              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-22                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-22                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-22                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-22                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-23                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-23                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.23.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-23                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-23 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-23                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-23 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-23                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-23 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-23                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-23 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-23                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-23                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l23 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l23                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l23 (view) (copy of Kcur-23) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-23                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l23 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-23 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-23                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-23 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-23 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l23 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l23                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l23 (view) (copy of Vcur-23 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-23 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l23 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l23 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l23                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l23 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l23 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l23 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l23                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l23 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l23 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-23 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-23                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_850                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l23 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-23 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_851                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_850                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_852                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l23 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_851                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_852                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-23                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-23                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-23                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-23                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-23                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-22                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-23                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-23                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-23                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-23                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.23.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-23                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-23                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-23                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-23                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-23                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-23                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-23               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-23                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-23                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-23                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.23.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-23              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-23                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-23                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-23                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-23                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-24                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-24                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.24.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-24                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-24 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-24                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-24 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-24                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-24 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-24                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-24 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-24                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-24                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l24 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l24                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l24 (view) (copy of Kcur-24) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-24                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l24 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-24 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-24                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-24 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-24 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l24 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l24                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l24 (view) (copy of Vcur-24 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-24 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l24 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l24 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l24                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l24 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l24 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l24 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l24                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l24 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l24 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-24 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-24                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_886                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l24 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-24 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_887                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_886                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_888                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l24 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_887                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_888                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-24                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-24                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-24                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-24                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-24                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-23                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-24                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-24                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-24                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-24                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.24.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-24                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-24                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-24                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-24                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-24                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-24                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-24               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-24                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-24                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-24                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.24.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-24              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-24                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-24                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-24                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-24                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-25                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-25                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.25.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-25                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-25 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-25                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-25 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-25                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-25 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-25                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-25 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-25                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-25                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l25 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l25                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l25 (view) (copy of Kcur-25) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-25                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l25 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-25 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-25                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-25 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-25 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l25 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l25                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l25 (view) (copy of Vcur-25 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-25 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l25 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l25 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l25                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l25 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l25 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l25 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l25                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l25 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l25 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-25 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-25                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_922                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l25 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-25 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_923                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_922                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_924                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l25 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_923                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_924                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-25                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-25                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-25                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-25                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-25                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-24                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-25                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-25                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-25                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-25                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.25.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-25                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-25                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-25                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-25                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-25                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-25                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-25               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-25                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-25                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-25                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.25.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-25              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-25                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-25                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-25                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-25                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-26                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-26                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.26.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-26                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-26 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-26                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-26 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-26                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-26 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-26                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-26 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-26                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-26                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l26 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l26                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l26 (view) (copy of Kcur-26) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-26                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l26 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-26 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-26                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-26 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-26 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l26 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l26                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l26 (view) (copy of Vcur-26 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-26 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l26 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l26 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l26                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l26 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l26 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l26 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l26                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l26 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l26 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-26 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-26                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_958                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l26 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-26 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_959                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_958                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_960                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l26 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_959                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_960                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-26                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-26                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-26                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-26                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-26                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-25                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-26                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-26                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-26                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-26                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.26.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-26                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-26                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-26                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-26                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-26                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-26                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-26               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-26                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-26                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-26                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.26.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-26              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-26                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-26                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-26                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-26                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-27                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-27                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.27.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-27                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-27 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-27                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-27 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-27                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-27 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-27                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-27 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-27                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-27                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l27 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l27                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l27 (view) (copy of Kcur-27) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-27                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l27 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-27 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-27                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-27 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-27 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l27 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l27                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l27 (view) (copy of Vcur-27 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-27 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l27 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l27 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l27                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l27 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l27 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l27 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l27                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l27 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l27 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-27 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-27                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_994                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l27 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-27 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_995                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_994                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_996                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l27 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_995                     
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_996                     
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-27                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-27                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-27                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-27                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-27                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-26                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-27                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-27                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-27                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-27                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.27.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-27                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-27                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-27                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-27                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-27                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-27                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-27               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-27                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-27                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-27                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.27.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-27              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-27                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-27                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-27                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-27                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-28                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-28                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.28.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-28                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-28 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-28                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-28 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-28                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-28 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-28                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-28 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-28                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-28                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l28 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l28                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l28 (view) (copy of Kcur-28) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-28                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l28 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-28 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-28                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-28 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-28 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l28 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l28                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l28 (view) (copy of Vcur-28 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-28 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l28 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l28 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l28                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l28 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l28 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l28 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l28                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l28 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l28 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-28 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-28                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1030                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l28 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-28 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1031                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_1030                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1032                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l28 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_1031                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_1032                    
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-28                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-28                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-28                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-28                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-28                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-27                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-28                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-28                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-28                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-28                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.28.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-28                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-28                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-28                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-28                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-28                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-28                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-28               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-28                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-28                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-28                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.28.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-28              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-28                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-28                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-28                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-28                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-29                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-29                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.29.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-29                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-29 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-29                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-29 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-29                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-29 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-29                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-29 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-29                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-29                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l29 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l29                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l29 (view) (copy of Kcur-29) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-29                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l29 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-29 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-29                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-29 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-29 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l29 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l29                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l29 (view) (copy of Vcur-29 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-29 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l29 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l29 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l29                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l29 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l29 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l29 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l29                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l29 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l29 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-29 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-29                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1066                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l29 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-29 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1067                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_1066                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1068                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l29 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_1067                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_1068                    
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-29                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-29                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-29                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-29                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-29                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-28                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-29                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-29                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-29                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-29                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.29.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-29                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-29                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-29                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-29                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-29                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-29                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-29               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-29                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-29                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-29                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.29.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-29              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-29                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-29                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-29                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-29                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-30                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-30                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.30.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-30                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-30 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-30                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-30 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-30                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-30 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-30                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-30 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-30                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-30                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l30 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l30                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l30 (view) (copy of Kcur-30) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-30                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l30 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-30 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-30                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-30 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-30 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l30 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l30                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l30 (view) (copy of Vcur-30 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-30 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l30 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l30 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l30                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l30 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l30 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l30 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l30                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l30 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l30 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-30 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-30                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1102                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l30 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-30 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1103                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_1102                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1104                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l30 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_1103                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_1104                    
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-30                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-30                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-30                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-30                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: attn_out-30                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: l_out-29                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-30                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-30                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-30                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-30                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.30.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-30                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-30                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-30                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-30                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-30                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-30                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-30               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 2 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-30                  
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-30                    
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-30                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.30.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-30              
    Type:       f32                      
    Dimensions: [14336 × 2 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-30                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-30                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-30                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-30                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_norm-31                  │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-31                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.31.attn_norm.weight      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.attn_q.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-31                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-31 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Qcur-31                      
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Qcur-31 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.attn_k.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-31                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-31 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Kcur-31                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Kcur-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  ROPE                     
Inputs:     3                        
    Tensor: Kcur-31 (reshaped)           
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
    Tensor: leaf_4                       
    Type:       i32                      
    Dimensions: [2 × 1 × 1 × 1]       
    Operation:  NONE                     
    Tensor: rope_freqs.weight            
    Type:       f32                      
    Dimensions: [64 × 1 × 1 × 1]      
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.attn_v.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 1024 × 1 × 1] 
    Operation:  NONE                     
    Tensor: attn_norm-31                 
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 8 × 2 × 1]     
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-31                      
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l31 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l31                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l31 (view) (copy of Kcur-31) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2048 × 1 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Kcur-31                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  ROPE                     
    Tensor: cache_k_l31 (view)           
    Type:       f16                      
    Dimensions: [2048 × 1 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-31 (reshaped)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [1024 × 2 × 1 × 1]    
Operation:  RESHAPE                  
Inputs:     1                        
    Tensor: Vcur-31                      
    Type:       f32                      
    Dimensions: [128 × 8 × 2 × 1]     
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Vcur-31 (reshaped) (transposed) │
────────────────────────────────────────
Type:       f32                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  TRANSPOSE                
Inputs:     1                        
    Tensor: Vcur-31 (reshaped)           
    Type:       f32                      
    Dimensions: [1024 × 2 × 1 × 1]    
    Operation:  RESHAPE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l31 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l31                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l31 (view) (copy of Vcur-31 (reshaped) (transposed)) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [2 × 1024 × 1 × 1]    
Operation:  CPY                      
Inputs:     2                        
    Tensor: Vcur-31 (reshaped) (transposed)
    Type:       f32                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  TRANSPOSE                
    Tensor: cache_v_l31 (view)           
    Type:       f16                      
    Dimensions: [2 × 1024 × 1 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l31 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 8 × 128 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_v_l31                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_v_l31 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [32 × 128 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_v_l31 (view)           
    Type:       f16                      
    Dimensions: [32 × 8 × 128 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l31 (view)            │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 8 × 32 × 1]    
Operation:  VIEW                     
Inputs:     1                        
    Tensor: cache_k_l31                  
    Type:       f16                      
    Dimensions: [1024 × 4096 × 1 × 1] 
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: cache_k_l31 (view) (permuted) │
────────────────────────────────────────
Type:       f16                      
Dimensions: [128 × 32 × 8 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: cache_k_l31 (view)           
    Type:       f16                      
    Dimensions: [128 × 8 × 32 × 1]    
    Operation:  VIEW                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: Qcur-31 (permuted)            │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: Qcur-31                      
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  ROPE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1138                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_k_l31 (view) (permuted)
    Type:       f16                      
    Dimensions: [128 × 32 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: Qcur-31 (permuted)           
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1139                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [32 × 2 × 32 × 1]     
Operation:  SOFT_MAX                 
Inputs:     2                        
    Tensor: node_1138                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  MUL_MAT                  
    Tensor: leaf_10                      
    Type:       f32                      
    Dimensions: [32 × 64 × 1 × 1]     
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1140                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 2 × 32 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: cache_v_l31 (view) (permuted)
    Type:       f16                      
    Dimensions: [32 × 128 × 8 × 1]    
    Operation:  PERMUTE                  
    Tensor: node_1139                    
    Type:       f32                      
    Dimensions: [32 × 2 × 32 × 1]     
    Operation:  SOFT_MAX                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor:  (permuted)                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128 × 32 × 2 × 1]    
Operation:  PERMUTE                  
Inputs:     1                        
    Tensor: node_1140                    
    Type:       f32                      
    Dimensions: [128 × 2 × 32 × 1]    
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: kqv_out-31                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  CONT                     
Inputs:     1                        
    Tensor:  (permuted)                  
    Type:       f32                      
    Dimensions: [128 × 32 × 2 × 1]    
    Operation:  PERMUTE                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: attn_out-31                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 2 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.attn_output.weight    
    Type:       q8_0                     
    Dimensions: [4096 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: kqv_out-31                   
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  CONT                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1144                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  GET_ROWS                 
Inputs:     2                        
    Tensor: attn_out-31                  
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: leaf_356                     
    Type:       i32                      
    Dimensions: [1 × 1 × 1 × 1]       
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: node_1145                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  GET_ROWS                 
Inputs:     2                        
    Tensor: l_out-30                     
    Type:       f32                      
    Dimensions: [4096 × 2 × 1 × 1]    
    Operation:  ADD                      
    Tensor: leaf_356                     
    Type:       i32                      
    Dimensions: [1 × 1 × 1 × 1]       
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_inp-31                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: node_1144                    
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  GET_ROWS                 
    Tensor: node_1145                    
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  GET_ROWS                 
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm-31                       │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: ffn_inp-31                   
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_norm-31                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm-31                      
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: blk.31.ffn_norm.weight       
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate-31                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 1 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.ffn_gate.weight       
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-31                  
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_silu-31                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 1 × 1 × 1]   
Operation:  UNARY                    
Inputs:     1                        
    Tensor: ffn_gate-31                  
    Type:       f32                      
    Dimensions: [14336 × 1 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_up-31                     │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 1 × 1 × 1]   
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.ffn_up.weight         
    Type:       q8_0                     
    Dimensions: [4096 × 14336 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_norm-31                  
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_gate_par-31               │
────────────────────────────────────────
Type:       f32                      
Dimensions: [14336 × 1 × 1 × 1]   
Operation:  MUL                      
Inputs:     2                        
    Tensor: ffn_silu-31                  
    Type:       f32                      
    Dimensions: [14336 × 1 × 1 × 1]   
    Operation:  UNARY                    
    Tensor: ffn_up-31                    
    Type:       f32                      
    Dimensions: [14336 × 1 × 1 × 1]   
    Operation:  MUL_MAT                  
─────────────────────────────────────────
────────────────────────────────────────
Tensor: ffn_out-31                    │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: blk.31.ffn_down.weight       
    Type:       q8_0                     
    Dimensions: [14336 × 4096 × 1 × 1] 
    Operation:  NONE                     
    Tensor: ffn_gate_par-31              
    Type:       f32                      
    Dimensions: [14336 × 1 × 1 × 1]   
    Operation:  MUL                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: l_out-31                      │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  ADD                      
Inputs:     2                        
    Tensor: ffn_out-31                   
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  MUL_MAT                  
    Tensor: ffn_inp-31                   
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: norm                          │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  RMS_NORM                 
Inputs:     1                        
    Tensor: l_out-31                     
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  ADD                      
─────────────────────────────────────────
────────────────────────────────────────
Tensor: result_norm                   │
────────────────────────────────────────
Type:       f32                      
Dimensions: [4096 × 1 × 1 × 1]    
Operation:  MUL                      
Inputs:     2                        
    Tensor: norm                         
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  RMS_NORM                 
    Tensor: output_norm.weight           
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  NONE                     
─────────────────────────────────────────
────────────────────────────────────────
Tensor: result_output                 │
────────────────────────────────────────
Type:       f32                      
Dimensions: [128256 × 1 × 1 × 1]  
Operation:  MUL_MAT                  
Inputs:     2                        
    Tensor: output.weight                
    Type:       q8_0                     
    Dimensions: [4096 × 128256 × 1 × 1] 
    Operation:  NONE                     
    Tensor: result_norm                  
    Type:       f32                      
    Dimensions: [4096 × 1 × 1 × 1]    
    Operation:  MUL                      
─────────────────────────────────────────
